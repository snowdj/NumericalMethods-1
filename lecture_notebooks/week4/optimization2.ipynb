{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization 2: Algorithms and Constraints\n",
    "\n",
    "Florian Oswald\n",
    "Sciences Po, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bracketing\n",
    "\n",
    "* A derivative-free method for *univariate* $f$\n",
    "* works only on **unimodal** $f$\n",
    "* (Draw choosing initial points and where to move next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](bracketing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Golden Ratio or Bracketing Search for 1D problems\n",
    "\n",
    "* A derivative-free method\n",
    "* a Bracketing method\n",
    "\t* find the local minimum of $f$ on $[a,b]$\n",
    "\t* select 2 interior points $c,d$ such that $a<c<d<b$\n",
    "\t\t* $f(c) \\leq f(d) \\implies$ min must lie in $[a,d]$. replace $b$ with $d$, start again with $[a,d]$\n",
    "\t\t* $f(c) > f(d) \\implies$ min must lie in $[c,b]$. replace $a$ with $c$, start again with $[c,b]$\n",
    "\t* how to choose $b,d$ though?\n",
    "\t* we want the length of the interval to be independent of whether we replace upper or lower bound\n",
    "\t* we want to reuse the non-replaced point from the previous iteration. \n",
    "\t* these imply the golden rule:\n",
    "\t* new point $x_i = a + \\alpha_i (b-a)$, where $\\alpha_1 = \\frac{3-\\sqrt{5}}{2},\\alpha_2=\\frac{\\sqrt{5}-1}{2}$\n",
    "\t* $\\alpha_2$ is known as the *golden ratio*, well known for it's role in renaissance art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Optim\n",
    "gr()\n",
    "f(x) = exp(x) - x^4\n",
    "plot(f,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "minf(x) = -f(x)\n",
    "brent = optimize(minf,0,2,Brent())\n",
    "golden = optimize(minf,0,2,GoldenSection())\n",
    "vline!([Optim.minimizer(brent)],label = \"brent\")\n",
    "vline!([Optim.minimizer(golden)], label = \"golden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f2 = x->sin(x) + 0.1*abs(x)\n",
    "x_arr = collect(range(3π/2-8.5, stop=3π/2+5.5, length=151))\n",
    "y_arr = f2.(x_arr) \n",
    "plot(x_arr,y_arr,legend = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ob = optimize(f2,1,5,Brent())\n",
    "vline!([Optim.minimizer(ob)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ob = optimize(f2,-2.5,2.5,Brent())\n",
    "vline!([Optim.minimizer(ob)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ob = optimize(f2,-2.5,10,Brent())\n",
    "vline!([Optim.minimizer(ob)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bisection Methods\n",
    "\n",
    "* Root finding: `Roots.jl`\n",
    "* Root finding in multivariate functions: [`IntervalRootFinding.jl`](https://github.com/JuliaIntervals/IntervalRootFinding.jl/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using Roots\n",
    "# find the zeros of this function:\n",
    "f(x) = exp(x) - x^4\n",
    "## bracketing\n",
    "fzero(f, 8, 9)      # 8.613169456441398\n",
    "fzero(f, -10, 0) # -0.8155534188089606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using IntervalRootFinding, IntervalArithmetic\n",
    "-10..10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = IntervalBox(1..3, 2..4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = @interval(0.1, 0.3)\n",
    "b = @interval(0.3, 0.6)\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts = roots(x->x^2 - 2, -10..10, IntervalRootFinding.Bisection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Rosenbrock Banana and Optim.jl\n",
    "\n",
    "* We can supply the objective function and - depending on the solution algorithm - the gradient and hessian as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using Optim\n",
    "using OptimTestProblems\n",
    "for (name, prob) in MultivariateProblems.UnconstrainedProblems.examples\n",
    "   println(name)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rosenbrock = MultivariateProblems.UnconstrainedProblems.examples[\"Rosenbrock\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Comparison Methods\n",
    "\n",
    "* We will now look at a first class of algorithms, which are very simple, but sometimes a good starting point.\n",
    "* They just *compare* function values.\n",
    "* *Grid Search* : Compute the objective function at $G=\\{x_1,\\dots,x_N\\}$ and pick the highest value of $f$. \n",
    "\t* This is very slow.\n",
    "\t* It requires large $N$.\n",
    "\t* But it's robust (will find global optimizer for large enough $N$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# grid search on rosenbrock\n",
    "grid = collect(-1.0:0.1:3);\n",
    "grid2D = [[i;j] for i in grid,j in grid];\n",
    "val2D = map(rosenbrock.f,grid2D);\n",
    "r = findmin(val2D);\n",
    "println(\"grid search results in minimizer = $(grid2D[r[2]])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Local Descent Methods\n",
    "\n",
    "* Applicable to multivariate problems\n",
    "* We are searching for a *local model* that provides some guidance in a certain region of $f$ over **where to go to next**.\n",
    "* Gradient and Hessian are informative about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Local Descent Outline\n",
    "\n",
    "All descent methods follow more or less this structure. At iteration $k$,\n",
    "\n",
    "1. Check if candidate $\\mathbf{x}^{(k)}$ satisfies stopping criterion:\n",
    "    * if yes: stop\n",
    "    * if no: continue\n",
    "2. Get the local *descent direction*  $\\mathbf{d}^{(k)}$, using gradient, hessian, or both.\n",
    "3. Set the *step size*, i.e. the length of the next step, $\\alpha^k$\n",
    "4. Get the next candidate via\n",
    "    $$\\mathbf{x}^{(k+1)} \\longleftarrow \\alpha^k\\mathbf{d}^{(k)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Line Search Strategy\n",
    "\n",
    "* An algorithm from the line search class  chooses a direction $\\mathbf{d}^{(k)} \\in \\mathbb{R}^n$ and searches along that direction starting from the current iterate $x_k \\in \\mathbb{R}^n$ for a new iterate $x_{k+1} \\in \\mathbb{R}^n$ with a lower function value.\n",
    "* After deciding on a direction $\\mathbf{d}^{(k)}$, one needs to decide the *step length* $\\alpha$ to travel by solving\n",
    "\t$$ \\min_{\\alpha>0} f(x_k + \\alpha \\mathbf{d}^{(k)}) $$\n",
    "* In practice, solving this exactly is too costly, so algos usually generate a sequence of trial values $\\alpha$ and pick the one with the lowest $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using LineSearches\n",
    "\n",
    "algo_hz = Optim.Newton(linesearch = HagerZhang())    # Both Optim.jl and IntervalRootFinding.jl export `Newton`\n",
    "res_hz = Optim.optimize(rosenbrock.f, rosenbrock.g!, rosenbrock.h!, rosenbrock.initial_x, method=algo_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Trust Region Strategy\n",
    "\n",
    "* First choose max step size, then the direction\n",
    "* Finds the next step $\\mathbf{x}^{(k+1)}$ by minimizing a model of $\\hat{f}$ over a *trust region*, centered on $\\mathbf{x}^{(k)}$\n",
    "    * 2nd order Tayloer approx of $f$ is common.\n",
    "* Radius $\\delta$ of trust region is changed based on how well $\\hat{f}$ fits $f$ in trust region.\n",
    "* Get $\\mathbf{x'}$ via\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\min_{\\mathbf{x'}} &\\quad \\hat{f}(\\mathbf{x'}) \\\\\n",
    "    \\text{subject to } &\\quad \\Vert \\mathbf{x}-\\mathbf{x'} \\leq \\delta \\Vert\n",
    "    \\end{aligned}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Optim.jl has a TrustRegion for Newton (see below for Newton's Method)\n",
    "NewtonTrustRegion(; initial_delta = 1.0, # The starting trust region radius\n",
    "                    delta_hat = 100.0, # The largest allowable trust region radius\n",
    "                    eta = 0.1, #When rho is at least eta, accept the step.\n",
    "                    rho_lower = 0.25, # When rho is less than rho_lower, shrink the trust region.\n",
    "                    rho_upper = 0.75) # When rho is greater than rho_upper, grow the trust region (though no greater than delta_hat).\n",
    "res = Optim.optimize(rosenbrock.f, rosenbrock.g!, rosenbrock.h!, rosenbrock.initial_x, method=NewtonTrustRegion())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Stopping criteria\n",
    "\n",
    "1. maximum number of iterations reached\n",
    "2. absolute improvement $|f(x) - f(x')| \\leq \\epsilon$\n",
    "3. relative improvement $|f(x) - f(x')| / |f(x)| \\leq \\epsilon$\n",
    "4. Gradient close to zero $|g(x)| \\approx 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent\n",
    "\n",
    "* Here we define\n",
    "    $$\\mathbf{g}^{(k)} = \\nabla f(\\mathbf{d}^{(k)})$$\n",
    "* And our descent becomes\n",
    "    $$\\mathbf{d}^{(k)} = -\\nabla \\frac{\\mathbf{g}^{(k)} }{\\Vert\\mathbf{g}^{(k)}\\Vert }$$\n",
    "* Minimizing wrt step size results in a jagged path (each direction is orthogonal to previous direction!)\n",
    "    $$\\alpha^{(k)} = \\arg \\min{\\alpha} f(\\mathbf{x}^{(k)} + \\alpha \\mathbf{d}^{(k)}) $$\n",
    "* *Conjugate* Gradient avoids this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Optim.jl again\n",
    "GradientDescent(; alphaguess = LineSearches.InitialPrevious(),\n",
    "                  linesearch = LineSearches.HagerZhang(),\n",
    "                  P = nothing,\n",
    "                  precondprep = (P, x) -> nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "GD = optimize(rosenbrock.f, rosenbrock.g!,[0.0, 0.0],GradientDescent())\n",
    "GD1 = optimize(rosenbrock.f, rosenbrock.g!,[0.0, 0.0],GradientDescent(),Optim.Options(iterations=5000))\n",
    "GD2 = optimize(rosenbrock.f, rosenbrock.g!,[0.0, 0.0],GradientDescent(),Optim.Options(iterations=50000))\n",
    "\n",
    "println(\"gradient descent = $GD\")\n",
    "println(\"\\n\")\n",
    "println(\"gradient descent 2 = $GD1\")\n",
    "println(\"\\n\")\n",
    "println(\"gradient descent 3 = $GD2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Second Order Methods\n",
    "\n",
    "### Newton's Method\n",
    "\n",
    "* We start with a 2nd order Taylor approx over x at step $k$:\n",
    "    $$q(x) = f(x^{(k)}) + (x - x^{(k)}) f'(x^{(k)}) + \\frac{(x - x^{(k)})^2}{2}f''(x^{(k)})$$\n",
    "* We form first order conditions (set it's root equal to zero) and rearrange to find the next step $k+1$:\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\frac{\\partial q(x)}{\\partial x} &= f'(x^{(k)}) + (x - x^{(k)}) f''(x^{(k)}) = 0 \\\\\n",
    "    x^{(k+1)} &= x^{(k)} - \\frac{f'(x^{(k)})}{f''(x^{(k)})}\n",
    "    \\end{aligned}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The same argument works for multidimensional functions by using Hessian and Gradient\n",
    "* We would get a descent $\\mathbf{d}^k$ by setting:\n",
    "    $$\\mathbf{d}^k = -\\frac{\\mathbf{g}^{k}}{\\mathbf{H}^{k}}$$\n",
    "* There are several options to avoid (often costly) computation of the Hessian $\\mathbf{H}$:\n",
    "1. Quasi-Newton updates $\\mathbf{H}$ starting from identity matrix\n",
    "2. Broyden-Fletcher-Goldfarb-Shanno (BFGS) does better with approx linesearch\n",
    "3. L-BFGS is the limited memory version for large problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "optimize(rosenbrock.f, rosenbrock.g!, rosenbrock.h!, [0.0, 0.0], Optim.Newton(),Optim.Options(show_trace=true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@show optimize(rosenbrock.f, rosenbrock.g!, rosenbrock.h!,  [-1.0, 3.0], BFGS());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# low memory BFGS\n",
    "@show optimize(rosenbrock.f, rosenbrock.g!, rosenbrock.h!,  [0.0, 0.0], LBFGS());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Direct Methods\n",
    "\n",
    "* No derivative information is used - *derivative free*\n",
    "* If it's very hard / impossible to provide gradient information, this is our only chance.\n",
    "* Direct methods use other criteria than the gradient to inform the next step (and ulimtately convergence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cyclic Coordinate Descent -- Taxicab search\n",
    "\n",
    "* We do a line search over each dimension, one after the other\n",
    "* *taxicab* because the path looks like a NYC taxi changing direction at each block.\n",
    "* given $\\mathbf{x}^{(1)}$, we proceed\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\mathbf{x}^{(2)} &= \\arg \\min_{x_1} f(x_1,x_2^{(1)},\\dots,x_n^{(1)}) \\\\\n",
    "    \\mathbf{x}^{(3)} &= \\arg \\min_{x_2} f(x_1^{(2)},x_2,x_3^{(2)}\\dots,x_n^{(2)}) \\\\    \n",
    "    \\end{aligned}\n",
    "    $$\n",
    "* unfortunately this can easily get stuck because it can only move in 2 directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# start to setup a basis function, i.e. unit vectors to index each direction:\n",
    "basis(i, n) = [k == i ? 1.0 : 0.0 for k in 1 : n]\n",
    "function cyclic_coordinate_descent(f, x, ε) \n",
    "    Δ, n = Inf, length(x)\n",
    "    while abs(Δ) > ε\n",
    "        x′ = copy(x) \n",
    "            for i in 1 : n\n",
    "                d = basis(i, n)\n",
    "                x = line_search(f, x, d) \n",
    "            end\n",
    "        Δ = norm(x - x′) \n",
    "    end\n",
    "    return x \n",
    "end  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### General Pattern Search\n",
    "\n",
    "* We search according to an arbitrary *pattern* $\\mathcal{P}$ of candidate points, anchored at current guess $\\mathbf{x}$.\n",
    "* With step size $\\alpha$ and set $\\mathcal{D}$ of directions\n",
    "    $$ \\mathcal{P} = {\\mathbf{x} + \\alpha \\mathbf{d} \\text{ for } \\mathbf{d}\\in\\mathcal{D} }$$\n",
    "* Convergence is guaranteed under conditions:\n",
    "    * $\\mathcal{D}$ must be a positive spanning set: at least one $\\mathbf{d}\\in\\mathcal{D}$ has a non-zero gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "function generalized_pattern_search(f, x, α, D, ε, γ=0.5) \n",
    "    y, n = f(x), length(x)\n",
    "    evals = 0\n",
    "    while α > ε\n",
    "        improved = false\n",
    "        for (i,d) in enumerate(D)\n",
    "            x′ = x + α*d \n",
    "            y′ = f(x′) \n",
    "            evals += 1\n",
    "            if y′ < y\n",
    "                x, y, improved = x′, y′, true\n",
    "                D = pushfirst!(deleteat!(D, i), d) \n",
    "                break\n",
    "            end \n",
    "        end\n",
    "        if !improved \n",
    "            α *= γ\n",
    "        end \n",
    "    end\n",
    "    println(\"$evals evaluations\")\n",
    "    return x \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "D = [[1,0],[0,1],[-1,-0.5]]\n",
    "D = [[1,0],[0,1]]\n",
    "y=generalized_pattern_search(rosenbrock.f,zeros(2),0.8,D,1e-6 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bracketing for Multidimensional Problems: Nelder-Mead\n",
    "\n",
    "* The Goal here is to find the simplex containing the local minimizer $x^*$\n",
    "* In the case where $f$ is n-D, this simplex has $n+1$ vertices\n",
    "* In the case where $f$ is 2-D, this simplex has $2+1$ vertices, i.e. it's a triangle.\n",
    "* The method proceeds by evaluating the function at all $n+1$ vertices, and by replacing the worst function value with a new guess.\n",
    "* this can be achieved by a sequence of moves:\n",
    "\t* reflect\n",
    "\t* expand\n",
    "\t* contract\n",
    "\t* shrink\n",
    "\tmovements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"center\" style=\"width: auto; margin-left: auto; margin-right: auto;\"> ![](optimization/neldermeadsteps.jpg) </div>\n",
    "\n",
    "* this is a very popular method. The matlab functions `fmincon` and `fminsearch` implements it.\n",
    "* When it works, it works quite fast.\n",
    "* No derivatives required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "nm=optimize(rosenbrock.f, [0.0, 0.0], NelderMead());\n",
    "nm.minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* But.\n",
    "\n",
    "\n",
    "## Bracketing for Multidimensional Problems: Comment on Nelder-Mead\n",
    "\n",
    "> Lagarias et al. (SIOPT, 1999):\n",
    "At present there is no function in any dimension greater than one, for which the original Nelder-Mead algorithm has been proved to converge to a minimizer.\n",
    "\n",
    ">Given all the known inefficiencies and failures of the Nelder-Mead algorithm [...], one might wonder why it is used at all, let alone why it is so extraordinarily popular.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## things to read up on\n",
    "\n",
    "* Divided Rectangles (DIRECT)\n",
    "* simulated annealing and other stochastic gradient methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stochastic Optimization Methods\n",
    "\n",
    "* Gradient based methods like steepest descent may be susceptible to getting stuck at local minima.\n",
    "* Randomly shocking the value of the descent direction may be a solution to this.\n",
    "* For example, one could modify our gradient descent from before to become\n",
    "\n",
    "\n",
    " $$\\mathbf{x}^{(k+1)} \\longleftarrow \\mathbf{x}^{(k)} +\\alpha^k\\mathbf{g}^{(k)} + \\mathbf{\\varepsilon}^{(k)}$$\n",
    "\n",
    "* where $\\mathbf{\\varepsilon}^{(k)} \\sim N(0,\\sigma_k^2)$, decreasing with $k$.\n",
    "* This *stochastic gradient descent* is often used when training neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simulated Annealing\n",
    "\n",
    "* We specify a *temperature* that controls the degree of randomness.\n",
    "* At first the temperature is high, letting the search jump around widely. This is to escape local minima.\n",
    "* The temperature is gradually decreased, reducing the step sizes. This is to find the local optimimum in the *best* region.\n",
    "* At every iteration $k$, we accept new point $\\mathbf{x'}$ with\n",
    "\n",
    "$$\n",
    "\\Pr(\\text{accept }\\mathbf{x'}) = \\begin{cases}\n",
    "1 & \\text{if }\\Delta y \\leq0 \\\\\n",
    "\\min(e^{\\Delta y / t},1) & \\text{if }\\Delta y > 0 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "* here $\\Delta y = f(\\mathbf{x'}) - f(\\mathbf{x})$, and $t$ is the *temperature*.\n",
    "* $\\Pr(\\text{accept }\\mathbf{x'})$ is called the **Metropolis Criterion**, building block of *Accept/Reject* algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# f: function\n",
    "# x: initial point\n",
    "# T: transition distribution\n",
    "# t: temp schedule, k_max: max iterations\n",
    "function simulated_annealing(f, x, T, t, k_max) \n",
    "    y = f(x)\n",
    "    ytrace = zeros(typeof(y),k_max)\n",
    "    x_best, y_best = x, y \n",
    "    for k in 1 : k_max\n",
    "        x′ = x + rand(T)\n",
    "        y′ = f(x′)\n",
    "        Δy = y′ - y\n",
    "        if Δy ≤ 0 || rand() < exp(-Δy/t(k))\n",
    "            x, y = x′, y′ \n",
    "        end\n",
    "        if y′ < y_best\n",
    "            x_best, y_best = x′, y′\n",
    "        end \n",
    "        ytrace[k] = y_best\n",
    "    end\n",
    "    return x_best,ytrace\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "function ackley(x, a=20, b=0.2, c=2π) \n",
    "    d = length(x)\n",
    "    return -a*exp(-b*sqrt(sum(x.^2)/d)) - exp(sum(cos.(c*xi) for xi in x)/d) + a + exp(1)\n",
    "end\n",
    "gr()\n",
    "surface(-30:0.1:30,-30:0.1:30,(x,y)->ackley([x, y]),cbar=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "p = Any[]\n",
    "using Distributions\n",
    "gr()\n",
    "niters = 1000\n",
    "temps = (1,10,25)\n",
    "push!(p,[plot(x->i/x,1:1000,title = \"tmp $i\",lw=2,ylims = (0,1),leg = false) for i in (1,10,25)]...)\n",
    "for sig in (1,5,25), t1 in (1,10,25)\n",
    "    y = simulated_annealing(ackley,[15,15],MvNormal(2,sig),x->t1/x,1000)[2][:]\n",
    "    push!(p,plot(y,title = \"sig = $sig\",leg=false,lw=1.5,color=\"red\",ylims = (0,20)))\n",
    "end\n",
    "plot(p...,layout = (4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Constraints\n",
    "\n",
    "Recall our core optimization problem:\n",
    "\n",
    "$$ \n",
    "\\min_{x\\in\\mathbb{R}^n} f(x)  \\text{ s.t. } x \\in \\mathcal{X}\n",
    "$$\n",
    "\n",
    "* Up to now, the feasible set was $\\mathcal{X} \\in \\mathbb{R}^n$. \n",
    "* In **constrained problems** $\\mathcal{X}$ is a subset thereof.\n",
    "* We already encountered *box constraints*, e.g. $x \\in [a,b]$.\n",
    "* Sometimes the contrained solution coincides with the unconstrained one, sometimes it does not.\n",
    "* There are *equality constraints* and *inequality constraints*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrange Multipliers\n",
    "\n",
    "* Used to optimize a function subject to equality constraints.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_x & f(x) \\\\\n",
    "\\text{subject to } & h(x) = 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where both $f$ and $h$ have continuous partial derivatives.\n",
    "\n",
    "* We look for contour lines of $f$ that are aligned to contours of $h(x) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In other words, we want to find the best $x$ s.t. $h(x) = 0$ and we have\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = \\lambda \\nabla h(x)\n",
    "$$\n",
    "\n",
    "for some *Lagrange Mutliplier* $\\lambda$\n",
    "* Notice that we need the scalar $\\lambda$ because the magnitudes of the gradients may be different.\n",
    "* We therefore form the the **Lagrangian**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x,\\lambda) = f(x) - \\lambda h(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Suppose we have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_x & -\\exp\\left( -\\left( x_1 x_2 - \\frac{3}{2} \\right)^2 - \\left(x_2 - \\frac{3}{2}\\right)^2 \\right) \\\\\n",
    "\\text{subject to } & x_1 - x_2^2 = 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We form the Lagrangiagn:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x_1,x_2,\\lambda) = -\\exp\\left( -\\left( x_1 x_2 - \\frac{3}{2} \\right)^2 - \\left(x_2 - \\frac{3}{2}\\right)^2 \\right) - \\lambda(x_1 - x_2^2)\n",
    "$$\n",
    "\n",
    "Then we compute the gradient wrt to $x_1,x_2,\\lambda$, set to zero and solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "gr()\n",
    "f(x1,x2) = -exp.(-(x1.*x2 - 3/2).^2 - (x2-3/2).^2)\n",
    "c(x1) = sqrt(x1)\n",
    "x=0:0.01:3.5\n",
    "contour(x,x,(x,y)->f(x,y),lw=1.5,levels=[collect(0:-0.1:-0.85)...,-0.887,-0.95,-1])\n",
    "plot!(c,0.01,3.5,label=\"\",lw=2,color=:black)\n",
    "scatter!([1.358],[1.165],markersize=5,markercolor=:red,label=\"Constr. Optimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* If we had multiple constraints ($l$), we'd just add them up to get\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{x},\\mathbf{\\lambda}) = f(\\mathbf{x}) - \\sum_{i=1}^l \\lambda_i h_i(\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inequality Constraints\n",
    "\n",
    "Suppose now we had\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_\\mathbf{x} & f(\\mathbf{x}) \\\\\n",
    "\\text{subject to } & g(\\mathbf{x}) \\leq 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which, if the solution lies right on the constraint *boundary*, means that\n",
    "\n",
    "$$\n",
    "\\nabla f - \\mu \\nabla g = 0\n",
    "$$\n",
    "\n",
    "for some scalar $\\mu$ - as before. \n",
    "\n",
    "* In this case, we say the **constraint is active**.\n",
    "* In the opposite case, i.e. the solution lies **inside** the contrained region, we way the contraint is **inactive**. \n",
    "* In that case, we are back to an *unconstrained* problem, look for $\\nabla f = 0$, and set $\\mu=0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the blue area shows the FEASIBLE SET\n",
    "contour(x,x,(x,y)->f(x,y),lw=1.5,levels=[collect(0:-0.1:-0.85)...,-0.887,-0.95,-1])\n",
    "plot!(c,0.01,3.5,label=\"\",lw=2,color=:black,fill=(0,0.5,:blue))\n",
    "scatter!([1.358],[1.165],markersize=5,markercolor=:red,label=\"Constr. Optimum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the blue area shows the FEASIBLE SET\n",
    "# NOW THE CONSTRAINT IS INACTIVE OR SLACK!\n",
    "c2(x1) = 1+sqrt(x1)\n",
    "contour(x,x,(x,y)->f(x,y),lw=1.5,levels=[collect(0:-0.1:-0.85)...,-0.887,-0.95,-1])\n",
    "plot!(c2,0.01,3.5,label=\"\",lw=2,color=:black,fill=(0,0.5,:blue))\n",
    "scatter!([1],[1.5],markersize=5,markercolor=:red,label=\"Unconstr. Optimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Infinity Step\n",
    "\n",
    "* We could do an **infinite step** to avoid *infeasible points*:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_{\\infty\\text{-step}} &= \\begin{cases}\n",
    "f(\\mathbf{x}) & \\text{if } g(\\mathbf{x}) \\leq 0 \\\\\n",
    "\\infty & \\text{else. } \n",
    "\\end{cases}\\\\\n",
    " &= f(\\mathbf{x}) + \\infty (g(\\mathbf{x} > 0)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* Unfortunately, this is discontinous and non-differentiable, i.e. hard to handle for algorithms.\n",
    "* Instead, we use a *linear penalty* $\\mu g(\\mathbf{x})$ on the objective if the constraint is violated.\n",
    "* The penalty provides a lower bound to $\\infty$:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{x},\\mu) = f(\\mathbf{x}) + \\mu g(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "* We can get back the infinite step by maximizing the penalty:\n",
    "\n",
    "$$\n",
    "f_{\\infty\\text{-step}} = \\max_{\\mu\\geq 0} \\mathcal{L}(\\mathbf{x},\\mu)\n",
    "$$\n",
    "\n",
    "* Every infeasible $\\mathbf{x}$ returns $\\infty$, all others return $f(\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kuhn-Karush-Tucker (KKT)\n",
    "\n",
    "* Our problem thus becomes\n",
    "\n",
    "$$\n",
    "\\min_\\mathbf{x} \\max_{\\mu\\geq 0} \\mathcal{L}(\\mathbf{x},\\mu)\n",
    "$$\n",
    "\n",
    "* This is called the **primal problem**. Optimizing this requires:\n",
    "\n",
    "\n",
    "1. $g(\\mathbf{x}^*) \\leq 0$. Point is feasible.\n",
    "2. $\\mu \\geq 0$. Penalty goes into the right direction. *Dual feasibility*.\n",
    "3. $\\mu g(\\mathbf{x}^*) = 0$. Feasible point on the boundary has $g(\\mathbf{x}) = 0$, otherwise $g(\\mathbf{x}) < 0$ and $\\mu =0$.\n",
    "4. $\\nabla f(\\mathbf{x}^*) - \\mu \\nabla g(\\mathbf{x}^*) = 0$. With an active constraint, we want parallel contours of objective and constraint. When inactive, our optimum just has $\\nabla f(\\mathbf{x}^*) = 0$, which means $\\mu = 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The preceding four conditions are called the Kuhn-Karush-Tucker (KKT) conditions. In the above order, and in general terms, they are:\n",
    "\n",
    "1. Feasibility\n",
    "2. Dual Feasibility\n",
    "3. Complementary Slackness\n",
    "4. Stationarity.\n",
    "\n",
    "The KKT conditions are the FONCs for problems with smooth constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Duality\n",
    "\n",
    "We can combine equality and inequality constraints:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{x},\\mathbf{\\lambda},\\mathbf{\\mu}) = f(\\mathbf{x}) + \\sum_{i} \\lambda_i h_i(\\mathbf{x}) + \\sum_j \\mu_j g_j(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "where, notice, we reverted the sign of $\\lambda$ since this is unrestricted.\n",
    "\n",
    "* The Primal problem is identical to the original problem and just as difficult to solve:\n",
    "\n",
    "$$\n",
    "\\min_\\mathbf{x} \\max_{\\mathbf{\\mu}\\geq 0,\\mathbf{\\lambda}} \\mathcal{L}(\\mathbf{x},\\mathbf{\\mu},\\mathbf{\\lambda})\n",
    "$$\n",
    "\n",
    "* The Dual problem reverses min and max:\n",
    "\n",
    "$$\n",
    "\\max_{\\mathbf{\\mu}\\geq 0,\\mathbf{\\lambda}} \\min_\\mathbf{x}  \\mathcal{L}(\\mathbf{x},\\mathbf{\\mu},\\mathbf{\\lambda})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dual Values\n",
    "\n",
    "* The *max-min-inequality* states that for any function $f(a,b)$\n",
    "\n",
    "$$\n",
    "\\max_\\mathbf{a} \\min_\\mathbf{b} f(\\mathbf{a},\\mathbf{b}) \\leq \\min_\\mathbf{b} \\max_\\mathbf{a} f(\\mathbf{a},\\mathbf{b}) \n",
    "$$\n",
    "\n",
    "* Hence, the solution to the dual is a lower bound to the solution of the primal problem.\n",
    "* The solution to the *dual function*, $\\min_\\mathbf{x}  \\mathcal{L}(\\mathbf{x},\\mathbf{\\mu},\\mathbf{\\lambda})$ is the min of a collection of linear functions, and thus always concave.\n",
    "* It is easy to optimize this.\n",
    "* In general, solving the dual is easy whenever minimizing $\\mathcal{L}$ wrt $x$ is easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Penalty Methods\n",
    "\n",
    "* We can convert the constrained problem back to unconstrained by adding penalty terms for constraint violoations.\n",
    "* A simple method could just count the number of violations:\n",
    "\n",
    "$$\n",
    "p_\\text{count}(\\mathbf{x}) = \\sum_{i} (h_i(\\mathbf{x}) \\neq 0 ) + \\sum_j  (g_j(\\mathbf{x} > 0)\n",
    "$$\n",
    "\n",
    "* and add this to the objective in an *unconstrained* problem with penalty $\\rho > 0$\n",
    "\n",
    "$$\n",
    "\\min_\\mathbf{x} f(\\mathbf{x}) + \\rho p_\\text{count}(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "* One can choose the penalty function: for example, a quadratic penaly will produce a smooth objective function\n",
    "* Notice that $\\rho$ needs to become very large sometimes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Augmented Lagrange Method\n",
    "\n",
    "* This is very similar, but specific to equality constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interior Point Method\n",
    "\n",
    "* Also called *barrier method*.\n",
    "* These methods make sure that the search point remains always feasible.\n",
    "* As one approaches the constraint boundary, the barrier function goes to infinity. Properties:\n",
    "\n",
    "1. $p_\\text{barrier}(\\mathbf{x})$ is continuous\n",
    "2. $p_\\text{barrier}(\\mathbf{x})$ is non negative\n",
    "3. $p_\\text{barrier}(\\mathbf{x})$ goes to infinitey as one approaches the constraint boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Barriers\n",
    "\n",
    "* Inverse Barrier\n",
    "\n",
    "$$\n",
    "p_\\text{barrier}(\\mathbf{x}) = -\\sum_i \\frac{1}{g_i(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "* Log Barrier\n",
    "\n",
    "$$\n",
    "p_\\text{barrier}(\\mathbf{x}) = -\\sum_i \\begin{cases}\\log(-g_i(\\mathbf{x})) & \\text{if } g_i(\\mathbf{x}) \\geq -1 \\\\\n",
    "0& \\text{else.} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "* The approach is as before, one transforms the problem to an unconstrained one and increases $\\rho$ until convergence:\n",
    "\n",
    "$$\n",
    "\\min_\\mathbf{x} f(\\mathbf{x}) + \\frac{1}{\\rho} p_\\text{barrier}(\\mathbf{x})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Examples\n",
    "\n",
    "$$ \n",
    "\\min_{x \\in \\mathbb{R}^2} \\sqrt{x_2} \\text{ subject to }\\begin{array}{c} \\\\\n",
    " x_2 \\geq 0 \\\\\n",
    " x_2 \\geq (a_1 x_1 + b_1)^3 \\\\\n",
    "x_2 \\geq (a_2 x_1 + b_2)^3 \n",
    "\\end{array}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Constrained Optimisation with [`NLopt.jl`](https://github.com/JuliaOpt/NLopt.jl)\n",
    "\n",
    "* We need to specify one function for each objective and constraint.\n",
    "* Both of those functions need to compute the function value (i.e. objective or constraint) *and* it's respective gradient. \n",
    "* `NLopt` expects contraints **always** to be formulated in the format \n",
    "\t$$ g(x) \\leq 0 $$\n",
    "     where $g$ is your constraint function\n",
    "* The constraint function is formulated for each constraint at $x$. it returns a number (the value of the constraint at $x$), and it fills out the gradient vector, which is the partial derivative of the current constraint wrt $x$.\n",
    "* There is also the option to have vector valued constraints, see the documentation.\n",
    "* We set this up as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using NLopt\n",
    "\n",
    "count = 0 # keep track of # function evaluations\n",
    "\n",
    "function myfunc(x::Vector, grad::Vector)\n",
    "    if length(grad) > 0\n",
    "        grad[1] = 0\n",
    "        grad[2] = 0.5/sqrt(x[2])\n",
    "    end\n",
    "\n",
    "    global count\n",
    "    count::Int += 1\n",
    "    println(\"f_$count($x)\")\n",
    "\n",
    "    sqrt(x[2])\n",
    "end\n",
    "\n",
    "function myconstraint(x::Vector, grad::Vector, a, b)\n",
    "    if length(grad) > 0\n",
    "        grad[1] = 3a * (a*x[1] + b)^2\n",
    "        grad[2] = -1\n",
    "    end\n",
    "    (a*x[1] + b)^3 - x[2]\n",
    "end\n",
    "\n",
    "opt = Opt(:LD_MMA, 2)\n",
    "lower_bounds!(opt, [-Inf, 0.])\n",
    "xtol_rel!(opt,1e-4)\n",
    "\n",
    "min_objective!(opt, myfunc)\n",
    "inequality_constraint!(opt, (x,g) -> myconstraint(x,g,2,0), 1e-8)\n",
    "inequality_constraint!(opt, (x,g) -> myconstraint(x,g,-1,1), 1e-8)\n",
    "\n",
    "(minfunc,minx,ret) = NLopt.optimize(opt, [1.234, 5.678])\n",
    "println(\"got $minfunc at $minx after $count iterations (returned $ret)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NLopt: Rosenbrock\n",
    "\n",
    "* Let's tackle the rosenbrock example again.\n",
    "* To make it more interesting, let's add an inequality constraint.\n",
    "\t$$ \\min_{x\\in \\mathbb{R}^2} (1-x_1)^2  + 100(x_2-x_1^2)^2  \\text{  subject to  } 0.8 - x_1^2 -x_2^2 \\geq 0 $$\n",
    "* in `NLopt` format, the constraint is $x_1 + x_2 - 0.8 \\leq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "function rosenbrockf(x::Vector,grad::Vector)\n",
    "    if length(grad) > 0\n",
    "\t    grad[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "\t    grad[2] = 200.0 * (x[2] - x[1]^2)\n",
    "    end\n",
    "    return (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "end\n",
    "function r_constraint(x::Vector, grad::Vector)\n",
    "    if length(grad) > 0\n",
    "\tgrad[1] = 2*x[1]\n",
    "\tgrad[2] = 2*x[2]\n",
    "\tend\n",
    "\treturn x[1]^2 + x[2]^2 - 0.8\n",
    "end\n",
    "opt = Opt(:LD_MMA, 2)\n",
    "lower_bounds!(opt, [-5, -5.0])\n",
    "min_objective!(opt,(x,g) -> rosenbrockf(x,g))\n",
    "inequality_constraint!(opt, (x,g) -> r_constraint(x,g))\n",
    "ftol_rel!(opt,1e-9)\n",
    "NLopt.optimize(opt, [-1.0,0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## JuMP.jl\n",
    "\n",
    "* Introduce [`JuMP.jl`](https://github.com/JuliaOpt/JuMP.jl)\n",
    "* JuMP is a mathematical programming interface for Julia. It is like AMPL, but for free and with a decent programming language.\n",
    "* The main highlights are:\n",
    "\t* It uses automatic differentiation to compute derivatives from your expression.\n",
    "\t* It supplies this information, as well as the sparsity structure of the Hessian to your preferred solver.\n",
    "\t* It decouples your problem completely from the type of solver you are using. This is great, since you don't have to worry about different solvers having different interfaces.\n",
    "\t* In order to achieve this, `JuMP` uses [`MathProgBase.jl`](https://github.com/JuliaOpt/MathProgBase.jl), which converts your problem formulation into a standard representation of an optimization problem.\n",
    "* Let's look at the readme\n",
    "* The technical citation is Lubin et al <cite data-cite=JuMP></cite>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## JuMP: Quick start guide\n",
    "\n",
    "* this is form the [quick start guide](http://www.juliaopt.org/JuMP.jl/v0.19.0/)\n",
    "* please check the docs, they are excellent.\n",
    "\n",
    "### Step 1: create a model\n",
    "\n",
    "* A model collects variables, objective function and constraints.\n",
    "* it defines a specific solver to be used.\n",
    "* JuMP makes it very easy to [swap out solver backends](http://www.juliaopt.org/JuMP.jl/dev/installation/) - This is very valuable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using GLPK\n",
    "model = Model(with_optimizer(GLPK.Optimizer))\n",
    "@variable(model, 0 <= x <= 2)\n",
    "@variable(model, 0 <= y <= 30)\n",
    "# next, we set an objective function\n",
    "@objective(model, Max, 5x + 3 * y)\n",
    "\n",
    "# maybe add a constraint called \"con\":\n",
    "@constraint(model, con, 1x + 5y <= 3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* At this stage `JuMP` has a mathematical representation of our model internalized\n",
    "* The `MathProgBase` machinery knows now exactly how to translate that to different solver interfaces\n",
    "* For us the only thing left: hit the button!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "JuMP.optimize!(model)\n",
    "\n",
    "# look at status\n",
    "termination_status(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# we query objective value and solutions\n",
    "@show objective_value(model)\n",
    "@show value(x)\n",
    "@show value(y)\n",
    "\n",
    "# as well as the value of the dual variable on the constraint\n",
    "@show dual(con);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The last call gets the *dual value associated with a constraint*\n",
    "* Economists most of the time call that the *value of the lagrange multiplier*. \n",
    "\n",
    "> For linear programs, a feasible dual on a `>=` constraint is nonnegative and a feasible dual on a `<=` constraint is nonpositive\n",
    "\n",
    "* This is different to some textbooks and has nothing to do with wether max or minimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# helpfully, we have this, which is always positive:\n",
    "shadow_price(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## JuMP handles...\n",
    "\n",
    "* linear programming\n",
    "* mixed-integer programming\n",
    "* second-order conic programming\n",
    "* semidefinite programming, and \n",
    "* nonlinear programming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# JuMP: nonlinear Rosenbrock Example\n",
    "# Instead of hand-coding first and second derivatives, you only have to give `JuMP` expressions for objective and constraints.\n",
    "# Here is an example.\n",
    "\n",
    "using Ipopt\n",
    "\n",
    "let\n",
    "\n",
    "    m = Model(with_optimizer(Ipopt.Optimizer))\n",
    "\n",
    "    @variable(m, x)\n",
    "    @variable(m, y)\n",
    "\n",
    "    @NLobjective(m, Min, (1-x)^2 + 100(y-x^2)^2)\n",
    "\n",
    "    JuMP.optimize!(m)\n",
    "    @show value(x)\n",
    "    @show value(y)\n",
    "    @show termination_status(m)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# not bad, right?\n",
    "# adding the constraint from before:\n",
    "\n",
    "let\n",
    "    \n",
    "    m = Model(with_optimizer(Ipopt.Optimizer))\n",
    "\n",
    "    @variable(m, x)\n",
    "    @variable(m, y)\n",
    "\n",
    "    @NLobjective(m, Min, (1-x)^2 + 100(y-x^2)^2)\n",
    "\n",
    "\n",
    "    @NLconstraint(m,x^2 + y^2 <= 0.8)\n",
    "\n",
    "    JuMP.optimize!(m)\n",
    "    @show value(x)\n",
    "    @show value(y)\n",
    "    @show termination_status(m)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## JuMP: Maximium Likelihood\n",
    "\n",
    "* Let's redo the maximum likelihood example in JuMP.\n",
    "* Let $\\mu,\\sigma^2$ be the unknown mean and variance of a random sample generated from the normal distribution.\n",
    "* Find the maximum likelihood estimator for those parameters!\n",
    "* density:\n",
    "\n",
    "$$ f(x_i|\\mu,\\sigma^2) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right) \n",
    "$$\n",
    "\n",
    "* Likelihood Function\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "L(\\mu,\\sigma^2) = \\Pi_{i=1}^N f(x_i|\\mu,\\sigma^2) =& \\frac{1}{(\\sigma \\sqrt{2\\pi})^n} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^N (x_i-\\mu)^2 \\right) \\\\\n",
    "\t =& \\left(\\sigma^2 2\\pi\\right)^{-\\frac{n}{2}} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^N (x_i-\\mu)^2 \\right) \n",
    "\\end{aligned} \n",
    "$$\n",
    "\n",
    "* Constraints: $\\mu\\in \\mathbb{R},\\sigma>0$\n",
    "* log-likelihood: \n",
    "\n",
    "$$ \\log L = l = -\\frac{n}{2} \\log \\left( 2\\pi \\sigma^2 \\right) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^N (x_i-\\mu)^2 $$\n",
    "\n",
    "* Let's do this in `JuMP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#  Copyright 2015, Iain Dunning, Joey Huchette, Miles Lubin, and contributors\n",
    "#  example modified \n",
    "using Distributions\n",
    "\n",
    "let\n",
    "    distrib = Normal(4.5,3.5)\n",
    "    n = 10000\n",
    "    \n",
    "    data = rand(distrib,n);\n",
    "    \n",
    "    m = Model(with_optimizer(Ipopt.Optimizer))\n",
    "\n",
    "    @variable(m, mu, start = 0.0)\n",
    "    @variable(m, sigma >= 0.0, start = 1.0)\n",
    "    \n",
    "    @NLobjective(m, Max, -(n/2)*log(2π*sigma^2)-sum((data[i] - mu) ^ 2 for i = 1:n)/(2*sigma^2))\n",
    "    \n",
    "    JuMP.optimize!(m)\n",
    "    @show termination_status(m)\n",
    "    println(\"μ = \", value(mu),\", mean(data) = \", mean(data))\n",
    "    println(\"σ^2 = \", value(sigma)^2, \", var(data) = \", var(data))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Constrained Problems (LPs)\n",
    "\n",
    "* Very similar to before, just that both objective and constraints are *linear*.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_\\mathbf{x} & \\mathbf{c}^T \\mathbf{x}\\\\\n",
    "\\text{subject to } & \\mathbf{w}_{LE}^{(i)T} \\mathbf{x} \\leq b_i \\text{ for  }i\\in{1,2,3,\\dots}\\\\\n",
    "& \\mathbf{w}_{GE}^{(j)T} \\mathbf{x} \\geq b_j \\text{ for  }j\\in{1,2,3,\\dots}\\\\\n",
    " & \\mathbf{w}_{EQ}^{(k)T} \\mathbf{x} = b_k \\text{ for  }k\\in{1,2,3,\\dots}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* Our initial JuMP example was of that sort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Standard Form\n",
    "\n",
    "* Usually LPs are given in *standard form*\n",
    "* All constraints are less-than inequalities\n",
    "* All choice variables are non-negative.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_\\mathbf{x}    & \\mathbf{c}^T \\mathbf{x}\\\\\n",
    "\\text{subject to } & \\mathbf{A}\\mathbf{x} \\leq b\\\\\n",
    "                   & \\mathbf{x}\\geq 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* Greater-than inequality constraints are inverted\n",
    "* equality constraints are split into two\n",
    "* $\\mathbf{x} = \\mathbf{x}^+ - \\mathbf{x}^-$ and we constrain both components to be positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Equality Form\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_\\mathbf{x}    & \\mathbf{c}^T \\mathbf{x}\\\\\n",
    "\\text{subject to } & \\mathbf{A}\\mathbf{x} = b\\\\\n",
    "                   & \\mathbf{x}\\geq 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* Can transform standard into equality form \n",
    "\n",
    "$$\n",
    "\\mathbf{A}\\mathbf{x} \\leq b \\to \\mathbf{A}\\mathbf{x} + \\mathbf{s}= b ,\\mathbf{s}\\geq 0\n",
    "$$\n",
    "\n",
    "* equality constraints are split into two\n",
    "* $\\mathbf{x} = \\mathbf{x}^+ - \\mathbf{x}^-$ and we constrain both components to be positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solving LPs\n",
    "\n",
    "* Simplex Algorithm operates on Equality Form\n",
    "* Moving from one vertex to the next of the feasible set, this is guaranteed to find the optimal solution if the problem is bounded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Cannery Problem\n",
    "\n",
    "* A can factory (a cannery) has plants in Seattle and San Diego\n",
    "* They need to decide how to serve markets New-York, Chicago, Topeka\n",
    "* Firm wants to \n",
    "    1. minimize shipping costs\n",
    "    2. shipments cannot exceed capacity\n",
    "    3. shipments must satisfy demand\n",
    "* Formalize that!\n",
    "* Plant capacity $cap_i$, demands $d_j$ and transport costs from plant $i$ to market  $j$, $dist_{i,j} c$ are all given.\n",
    "* Let $\\mathbf{x}$ be a matrix with element $x_{i,j}$ for number of cans shipped from $i$ to $j$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From Maths ...\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_\\mathbf{x}    & \\sum_{i=1}^2 \\sum_{j=1}^3 dist_{i,j}c \\times x_{i,j}\\\\\n",
    "\\text{subject to } & \\sum_{j=1}^3 x(i,j) \\leq cap_i , \\forall i \\\\\n",
    "                   & \\sum_{i=1}^2 x(i,j) \\geq d_j , \\forall j \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# ... to JuMP\n",
    "# https://github.com/JuliaOpt/JuMP.jl/blob/release-0.19/examples/cannery.jl\n",
    "#  Copyright 2017, Iain Dunning, Joey Huchette, Miles Lubin, and contributors\n",
    "#  This Source Code Form is subject to the terms of the Mozilla Public\n",
    "#  License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "#  file, You can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "#############################################################################\n",
    "# JuMP\n",
    "# An algebraic modeling language for Julia\n",
    "# See http://github.com/JuliaOpt/JuMP.jl\n",
    "#############################################################################\n",
    "\n",
    "using JuMP, GLPK, Test\n",
    "const MOI = JuMP.MathOptInterface\n",
    "\n",
    "\"\"\"\n",
    "    example_cannery(; verbose = true)\n",
    "JuMP implementation of the cannery problem from Dantzig, Linear Programming and\n",
    "Extensions, Princeton University Press, Princeton, NJ, 1963.\n",
    "Author: Louis Luangkesorn\n",
    "Date: January 30, 2015\n",
    "\"\"\"\n",
    "function example_cannery(; verbose = true)\n",
    "    plants = [\"Seattle\", \"San-Diego\"]\n",
    "    markets = [\"New-York\", \"Chicago\", \"Topeka\"]\n",
    "\n",
    "    # Capacity and demand in cases.\n",
    "    capacity = [350, 600]\n",
    "    demand = [300, 300, 300]\n",
    "\n",
    "    # Distance in thousand miles.\n",
    "    distance = [2.5 1.7 1.8; 2.5 1.8 1.4]\n",
    "\n",
    "    # Cost per case per thousand miles.\n",
    "    freight = 90\n",
    "\n",
    "    num_plants = length(plants)\n",
    "    num_markets = length(markets)\n",
    "\n",
    "    cannery = Model(with_optimizer(GLPK.Optimizer))\n",
    "\n",
    "    @variable(cannery, ship[1:num_plants, 1:num_markets] >= 0)\n",
    "\n",
    "    # Ship no more than plant capacity\n",
    "    @constraint(cannery, capacity_con[i in 1:num_plants],\n",
    "        sum(ship[i,j] for j in 1:num_markets) <= capacity[i]\n",
    "    )\n",
    "\n",
    "    # Ship at least market demand\n",
    "    @constraint(cannery, demand_con[j in 1:num_markets],\n",
    "        sum(ship[i,j] for i in 1:num_plants) >= demand[j]\n",
    "    )\n",
    "\n",
    "    # Minimize transporatation cost\n",
    "    @objective(cannery, Min, sum(distance[i, j] * freight * ship[i, j]\n",
    "        for i in 1:num_plants, j in 1:num_markets)\n",
    "    )\n",
    "\n",
    "    JuMP.optimize!(cannery)\n",
    "\n",
    "    if verbose\n",
    "        println(\"RESULTS:\")\n",
    "        for i in 1:num_plants\n",
    "            for j in 1:num_markets\n",
    "                println(\"  $(plants[i]) $(markets[j]) = $(JuMP.value(ship[i, j]))\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @test JuMP.termination_status(cannery) == MOI.OPTIMAL\n",
    "    @test JuMP.primal_status(cannery) == MOI.FEASIBLE_POINT\n",
    "    @test JuMP.objective_value(cannery) == 151200.0\n",
    "end\n",
    "example_cannery()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discrete Optimization / Integer Programming\n",
    "\n",
    "* Here the choice variable is contrained to come from a discrete set $\\mathcal{X}$. \n",
    "* If this set is $\\mathcal{X} = \\mathbb{N}$, we have an **integer program**\n",
    "* If only *some* $x$ have to be discrete, this is a **mixed integer program**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_\\mathbf{x}    & x_1 + x_2\\\\\n",
    "\\text{subject to } & ||\\mathbf{x}|| \\leq 2\\\\\n",
    "                   & \\mathbf{x} \\in \\mathbb{N}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* continuous optimum is $(-\\sqrt{2},-\\sqrt{2})$ and objective is $y=-2\\sqrt{2}=-2.828$\n",
    "* Integer constrained problem is only delivering $y=-2$, and $\\mathbf{x}^*\\in {(-2,0),(-1,-1),(0,-2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = -3:0.01:3\n",
    "dx = repeat(range(-3,stop = 3, length = 7),1,7)\n",
    "contourf(x,x,(x,y)->x+y,color=:blues)\n",
    "scatter!(dx,dx',legend=false,markercolor=:white)\n",
    "plot!(x->sqrt(4-x^2),-2,2,c=:white)\n",
    "plot!(x->-sqrt(4-x^2),-2,2,c=:white)\n",
    "scatter!([-2,-1,0],[0,-1,-2],c=:red)\n",
    "scatter!([-sqrt(2)],[-sqrt(2)],c=:red,markershape=:cross,markersize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Rounding\n",
    "\n",
    "* One solution is to just *round the continuous solution to the nearest integer*\n",
    "* We compute the **relaxed** problem, i.e. the one where $x$ is continuous.\n",
    "* Then we round up or down.\n",
    "* Can go terribly wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cutting Planes\n",
    "\n",
    "* This is an exact method\n",
    "* We solve the relaxed problem first.\n",
    "* Then we add linear constraints that result in the solution becoming integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Branch and Bound\n",
    "\n",
    "* This enumerates all possible soultions.\n",
    "* Branch and bound does this, without having to compute all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: The Knapsack Problem\n",
    "\n",
    "* We are packing our knapsack for a trip but only have space for the most valuable items.\n",
    "* We have $x_i=0$ if item $i$ is not in the sack, 1 else.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_x & - \\sum_{i=1}^n v_i x_i \\\\\n",
    "\\text{s.t. } & \\sum_{i=1}^n w_i x_i \\leq w_{max} \\\\\n",
    "w_i \\in \\mathbb{N}_+,  & v_i \\in \\mathbb{R}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* If ther are $n$ items, we have $2^n$ possible design vectors.\n",
    "* But there is a useful recursive relationship.\n",
    "* If we solved $n-1$ knapsack problems so far and deliberate about item $n$\n",
    "    * If it's not worth including item $n$, then the solution **is** the knapsack problem for $n-1$ items and capacity $w_{\\max}$\n",
    "    * If it IS worth including it: solution will have value of knapsack with $n-1$ items and reduced capacity, plus the value of the new item\n",
    "* This **is** dynamic progamming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knacksack Recursion\n",
    "\n",
    "* In particular, the recursion looks like this:\n",
    "\n",
    "$$\n",
    "\\text{knapsack}\\left(i,w_{\\text{max}}\\right)=\\begin{cases}\n",
    "0 & \\text{if}i=0\\\\\n",
    "\\text{knapsack}\\left(i-1,w_{\\text{max}}\\right) & \\text{if}w_{i}>w_{\\text{max}}\\\\\n",
    "\\max\\begin{cases}\n",
    "\\text{knapsack}\\left(i-1,w_{\\text{max}}\\right) & \\text{(discard new item)}\\\\\n",
    "\\text{knapsack}\\left(i-1,w_{\\text{max}}-w_{i}\\right)+v_{i} & \\text{(include new item)}\n",
    "\\end{cases} & \\text{else.}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#  Copyright 2017, Iain Dunning, Joey Huchette, Miles Lubin, and contributors\n",
    "#  This Source Code Form is subject to the terms of the Mozilla Public\n",
    "#  License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "#  file, You can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "#############################################################################\n",
    "# JuMP\n",
    "# An algebraic modeling langauge for Julia\n",
    "# See http://github.com/JuliaOpt/JuMP.jl\n",
    "#############################################################################\n",
    "# knapsack.jl\n",
    "#\n",
    "# Solves a simple knapsack problem:\n",
    "# max sum(p_j x_j)\n",
    "#  st sum(w_j x_j) <= C\n",
    "#     x binary\n",
    "#############################################################################\n",
    "\n",
    "using JuMP, Cbc, LinearAlgebra\n",
    "\n",
    "let\n",
    "\n",
    "    # Maximization problem\n",
    "    m = Model(with_optimizer(Cbc.Optimizer))\n",
    "    \n",
    "    @variable(m, x[1:5], Bin)\n",
    "    \n",
    "    profit = [ 5, 3, 2, 7, 4 ]\n",
    "    weight = [ 2, 8, 4, 2, 5 ]\n",
    "    capacity = 10\n",
    "    \n",
    "    # Objective: maximize profit\n",
    "    @objective(m, Max, dot(profit, x))\n",
    "    \n",
    "    # Constraint: can carry all\n",
    "    @constraint(m, dot(weight, x) <= capacity)\n",
    "    \n",
    "    # Solve problem using MIP solver\n",
    "    JuMP.optimize!(m)\n",
    "    \n",
    "    println(\"Objective is: \", JuMP.objective_value(m))\n",
    "    println(\"Solution is:\")\n",
    "    for i = 1:5\n",
    "        print(\"x[$i] = \", JuMP.value(x[i]))\n",
    "        println(\", p[$i]/w[$i] = \", profit[i]/weight[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
